{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "SWATI_GHOSH_CSE_6240.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uUxdPky75RG6",
        "outputId": "5564de81-06dc-4f7e-aeac-0a01fb5de8b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UIpeJ8VmR1TX",
        "colab": {}
      },
      "source": [
        "#Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import re\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from copy import deepcopy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d_6LWyLS7sYl",
        "outputId": "3f187516-01f9-47b1-b9c8-7efbbdb1e809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CIvs0LVJR1Te",
        "outputId": "86288256-da99-4d71-a343-c12435e4c503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# Reading in the data\n",
        "train = pd.read_csv(\"/content/drive/My Drive/WebProject/labeledTrainData.csv\", delimiter=\"\\t\",names=[\"tweet\", \"label\", \"labelValue\"])\n",
        "train[\"label\"].replace({\"spam\": \"neutral\", \"normal\": \"neutral\"}, inplace=True)\n",
        "train.head()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>labelValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beats by Dr. Dre urBeats Wired In-Ear Headphon...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @Papapishu: Man it would fucking rule if we...</td>\n",
              "      <td>abusive</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It is time to draw close to Him &amp;#128591;&amp;#127...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>if you notice me start to act different or dis...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Forget unfollowers, I believe in growing. 7 ne...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet    label  labelValue\n",
              "0  Beats by Dr. Dre urBeats Wired In-Ear Headphon...  neutral           4\n",
              "1  RT @Papapishu: Man it would fucking rule if we...  abusive           4\n",
              "2  It is time to draw close to Him &#128591;&#127...  neutral           4\n",
              "3  if you notice me start to act different or dis...  neutral           5\n",
              "4  Forget unfollowers, I believe in growing. 7 ne...  neutral           3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ano1yq7oR1Th",
        "colab": {}
      },
      "source": [
        "def preprocess_review(review):\n",
        "    \"\"\"Helper function to clean the reviews.\n",
        "\n",
        "     Arg: review: review text.\n",
        "     Returns: clean_review : Cleaned reviews\n",
        "\n",
        "     You should carry out the following steps.\n",
        "     1. Remove HTML Tags.\n",
        "     2. Remove non-letter characters.\n",
        "     3. Convert to lower case.\n",
        "     4. Remove stopwords.\n",
        "    \"\"\"\n",
        "\n",
        "    #Write your code below.\n",
        "    textwithoutHTML = BeautifulSoup(review).get_text()\n",
        "    \n",
        "    nonLetters = re.sub(\"[^a-zA-Z]\",\" \",textwithoutHTML)\n",
        "    \n",
        "    lowerCase = nonLetters.lower().split()\n",
        "\n",
        "    \n",
        "    stopWords = set(stopwords.words(\"english\"))                  \n",
        "\n",
        "    meaningful_words = [w for w in lowerCase if not w in stopWords]   \n",
        "\n",
        "    clean_review = (\" \".join(meaningful_words))\n",
        "    return clean_review\n",
        "\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FJERbiU0R1Tj",
        "colab": {}
      },
      "source": [
        "\n",
        "#Clean the reviews and add them to the list below\n",
        "cleaned_reviews = []\n",
        "cleaned_test_reviews = []\n",
        "#Write your code below.\n",
        "\n",
        "\n",
        "num_reviews = train[\"tweet\"].size\n",
        "#num_rev_t = test[\"review\"].size\n",
        "\n",
        "for i in range(0, num_reviews):\n",
        "    cleaned_reviews.append((preprocess_review(train[\"tweet\"][i])))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urCR0VMaR1Tn",
        "colab": {}
      },
      "source": [
        "def design_matrix(cleaned_reviews):\n",
        "\n",
        "    \n",
        "    #1 Generating bag of words with scikit's Count vectorizer\n",
        "    \n",
        "    cv = CountVectorizer(analyzer = \"word\",   \\\n",
        "                             tokenizer = None,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = None,   \\\n",
        "                             max_features = 5000)\n",
        "    \n",
        "    X_counts = cv.fit_transform(cleaned_reviews)\n",
        "    \n",
        "    #will use it later while testing on the test set\n",
        "    pickle.dump(cv, open(\"vectorizer.pickle\", \"wb\"))\n",
        "\n",
        "    \n",
        "    #2. \n",
        "    #using X_counts to prepare X_binary\n",
        "    X_binary = deepcopy(X_counts)\n",
        "    X_binary[X_binary > 0] = 1\n",
        "   \n",
        "\n",
        "    #3. Computing the tfidf values\n",
        "    tfidf_transformer=TfidfTransformer(smooth_idf=False)\n",
        "    tfidf_transformer.fit(X_counts)\n",
        "    X_tfidf=tfidf_transformer.transform(X_counts)\n",
        "    \n",
        "     #will use it later while testing on the test set\n",
        "    pickle.dump(tfidf_transformer, open(\"tfidf.pickle\", \"wb\"))\n",
        "\n",
        "    #4. Generating an imbalanced dataset\n",
        "    X_binary_imbalance = []\n",
        "    imbalance_train = []\n",
        "    \n",
        "    pos_sent = train[train[\"label\"] == 1] #get positive sentiment data\n",
        "    pos_sent = pos_sent.sample(frac = 0.75, random_state = 0) #select data randomly\n",
        "    imbalance_train = train.drop(pos_sent.index) # delete the data belonging to those indexes\n",
        "    \n",
        "    X_binary_imbalance = X_binary[imbalance_train.index] #use the skewed datset to get X_binary_imbalance\n",
        "    \n",
        "\n",
        "    return X_counts,X_binary,X_tfidf,X_binary_imbalance,imbalance_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "POPvMtKER1Tp",
        "colab": {}
      },
      "source": [
        "\n",
        "X_counts,X_binary,X_tfidf,X_binary_imbalance,imbalance_train = design_matrix(cleaned_reviews)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hyGBeT9w7DKU",
        "outputId": "9eb6e817-4938-4f9e-9e8b-509f20da6c49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_counts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<99996x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 815121 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5kt4EPPLR1Tx",
        "outputId": "a08d27d2-4d8e-4bd7-d554-dfa341e73d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_binary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<99996x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 815121 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xBH1DKHuR1T1",
        "outputId": "bf957d59-57d1-4da9-a6fb-6cc98d8c9124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_tfidf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<99996x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 815121 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hcHBxl31R1T7",
        "outputId": "5c243f52-7b35-460e-b75b-45adc07b684b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_binary_imbalance"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<99996x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 815121 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LRPAXIfDR1T_",
        "colab": {}
      },
      "source": [
        "# Obtain the label on the original train set and imbalance train set\n",
        "train_sentiment = train[\"label\"].values\n",
        "train_sentiment = train_sentiment[:50000]\n",
        "\n",
        "imbalance_train_sentiment = imbalance_train[\"label\"].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t9La4ICibWl6",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random as rd\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.svm import LinearSVC \n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.utils.fixes import loguniform\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N9K2mD7pe9Bc",
        "colab": {}
      },
      "source": [
        "def calculateF1(X, y, k = 5):\n",
        "    \"\"\"calculateF1(X, y, k = 5) return two list which record all randomly selected c(in the interval (1e-4, 1e4))\n",
        "     and corresponding F1 scores.\n",
        "\n",
        "     Args: X: Features\n",
        "           y: Label of sentiment\n",
        "           k: Number of Cross-validation\n",
        "\n",
        "     Returns: c_list: List of all c values.\n",
        "              f1_list: Corresponding F1 Scores.\n",
        "    \"\"\"\n",
        "    rd.seed(0) #Setting a common seed\n",
        "\n",
        "    #Write your code here.\n",
        "    c_list = []\n",
        "    f1_list = []\n",
        "    cross_val = KFold(n_splits=k)\n",
        "    \n",
        "    \n",
        "    for i in range(10):\n",
        "        i = rd.uniform(-4, 4)\n",
        "        c = 10**i\n",
        "        f1_sum = 0\n",
        "        model = LinearSVC(C = c)        \n",
        "        fscores = cross_val_score(model, X, y, cv=cross_val, scoring='f1_weighted')\n",
        "        fscores = fscores.mean()\n",
        "        c_list.append(c)\n",
        "        f1_list.append(fscores)\n",
        "        \n",
        "  \n",
        "    return c_list, f1_list\n",
        "        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ah82TDqCgKaN",
        "colab": {}
      },
      "source": [
        "def findBestC(X, y, k = 5):\n",
        "    \"\"\"findBestC(X, y, k) return the best performance c, and the improvement(difference between best and worst f1_scores)/\n",
        "     Args: X: Features\n",
        "           y: Label of sentiment\n",
        "           k: Number of Cross-validation\n",
        "     Returns: c_best: C value with best f1_score.\n",
        "              improvement: difference between best and worst f1_score.\n",
        "    \"\"\"\n",
        "    #Write your code here.\n",
        "    c_list, f1_list = calculateF1(X, y, k = 5)\n",
        "    #for i in range (len(c_list)):\n",
        "      #print (\"C:{} F:{}\".format(c_list[i], f1_list[i]))\n",
        "\n",
        "    bestf1 = np.amax(f1_list)\n",
        "    worstf1 = np.amin(f1_list)\n",
        "    improvement   = bestf1 - worstf1\n",
        "    indexb = np.argmax(f1_list)\n",
        "    c_best = c_list[indexb]    \n",
        "    \n",
        "    return c_best,improvement"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AFjJKZKelYl5",
        "colab": {}
      },
      "source": [
        "def findImprovement(X,train_sentiment,test_size = 0.2, random_state = 0):\n",
        "    \"\"\" Find the improvement in F1-Score of the design Matrix(X) using previous utility functions and the test_f1_score using the best C.\n",
        "\n",
        "      Args: X: Design Matrix\n",
        "            train_sentiment: Sentiments of the training data\n",
        "            test_size: Split it as 80:20\n",
        "            random_state: Seed\n",
        "\n",
        "      Returns:\n",
        "            c_best: The best possible c value\n",
        "            improvement: improvement in F1-Score using the design Matrix(X).\n",
        "            f1_s: Test F1 Score.\n",
        "            \n",
        "\n",
        "      You should carry out the following Steps:\n",
        "      1. Split the data using the above parameters.\n",
        "      2. Find out the best c and the improvement. (use 5-fold Cross Validation.)\n",
        "      3. Find out the test f1 score with this c.\n",
        "    \"\"\"\n",
        "    #Write your code here.\n",
        "    train_ip, test_ip, train_op, test_op = train_test_split(X,\n",
        "                                                          train_sentiment,\n",
        "                                                          stratify=train_sentiment,\n",
        "                                                            test_size = 0.2,\n",
        "                                                            random_state=0)\n",
        "                \n",
        "    c_best, improvement = findBestC(train_ip, train_op, k = 5)\n",
        "    model = LinearSVC(C = c_best)\n",
        "    model.fit(train_ip, train_op)\n",
        "    test_pred = model.predict(test_ip)\n",
        "    f1_s = f1_score(test_op,test_pred,average='weighted')\n",
        "    \n",
        "    \n",
        "\n",
        "    return c_best,improvement,f1_s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vtON_6r5jgTL",
        "outputId": "d469e092-c8b6-49c5-9630-7b16d9996e93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#Print the improvement using X_counts and the test f1_score using the best c.\n",
        "#Write your code here.\n",
        "c_best,improvement,f1_s = findImprovement(X_counts,train_sentiment)\n",
        "\n",
        "print(\"The improvement using X_counts is {} and f1_score is {} with best c {}\".format(improvement,f1_s,c_best))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The improvement using X_counts is 0.02750623944746411 and f1_score is 0.9063935254854274 with best c 0.173569374988568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IygnGs8blBu-",
        "outputId": "e0729652-fd84-41d0-e1aa-abd25373a208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Retrain the classifier using the entire learning set with c_best\n",
        "#Write your code here.\n",
        "model = svm.LinearSVC(C = c_best)\n",
        "model.fit(X_counts, train_sentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=0.010093707860257255, class_weight=None, dual=True,\n",
              "          fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
              "          max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
              "          tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sRHMJO2os_tc"
      },
      "source": [
        "#### 3.2.3 Tune an SVM classifier using X_tf_idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xnm8PdFWtGE9",
        "outputId": "5b789e19-d9fb-4081-a7d7-9f06df1ff803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#Print the improvement using X_tf_idf and the test f1_score using the best c.\n",
        "#Write your code here.\n",
        "c_best,improvement,f1_s = findImprovement(X_tfidf,train_sentiment)\n",
        "print(\"The improvement using X_tfidf is {} and f1_score is {} with best c {}\".format(improvement,f1_s,c_best))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The improvement using X_tfidf is 0.02989457480753155 and f1_score is 0.9025273788948042 with best c 0.6497939047431794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KWXXKrgGtU-r",
        "outputId": "c507207b-060d-4f1c-d3e2-026a52f50435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Retrain svm using all X_tfidf data\n",
        "#Write your code here.\n",
        "model = svm.LinearSVC(C = c_best)\n",
        "model.fit(X_tfidf, train_sentiment)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=0.6497939047431794, class_weight=None, dual=True,\n",
              "          fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
              "          max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
              "          tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZy1W2wCNRrU",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import learning_curve"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQYNGVZYugpY",
        "colab": {}
      },
      "source": [
        "training_instances = [100, 500, 1000, 2000, 3000, 4000, 5000, 7500, 10000, 15000, 20000]\n",
        "#Use the learning_curve module to generate mean train and test scores and plot them with X-axis being the number of training instances and Y-axis.\n",
        "#Please add appropriate title,labels and legends.\n",
        "#Write your code here.\n",
        "tr, train_scores, test_scores = learning_curve(LogisticRegression(max_iter=500),\n",
        "                                               X_counts, \n",
        "                                               train_sentiment,\n",
        "                                               cv = 5,\n",
        "                                               train_sizes = training_instances)\n",
        "\n",
        "\n",
        "train_mean =  - train_scores.mean(axis = 1) #mean across rows (axis=1)\n",
        "test_mean =  - test_scores.mean(axis = 1)\n",
        "#print (\"train mean\",train_mean)\n",
        "#print (\"test mean\",test_mean)\n",
        "# learning curve\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.grid()\n",
        "plt.title(\"Learning Curve X_count\")\n",
        "plt.xlabel(\"Training sizes\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.plot(training_instances, train_mean, 'o-', color = \"r\", label = \"Training error\")\n",
        "plt.plot(training_instances, test_mean, 'o-', color = \"g\", label = \"Testing error\")\n",
        "plt.legend(loc = \"best\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}