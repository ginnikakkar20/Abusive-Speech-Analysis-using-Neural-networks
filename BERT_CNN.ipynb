{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_BERT_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzODz9UnLG9l",
        "colab_type": "code",
        "outputId": "27fa50a1-3a3d-49fc-8ffa-00a27a7d9ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install tweet-preprocessor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import re\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from copy import deepcopy\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import PorterStemmer \n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import preprocessor as p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/f8/810ec35c31cca89bc4f1a02c14b042b9ec6c19dd21f7ef1876874ef069a6/tweet-preprocessor-0.5.0.tar.gz\n",
            "Building wheels for collected packages: tweet-preprocessor\n",
            "  Building wheel for tweet-preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tweet-preprocessor: filename=tweet_preprocessor-0.5.0-cp36-none-any.whl size=7947 sha256=f2f6a505a21bace97d633fe5c864af0358a44f6d2f8cb1e4cddf17119e6eca10\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/27/cc/49938e98a2470802ebdefae9d2b3f524768e970c1ebbe2dc4a\n",
            "Successfully built tweet-preprocessor\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.5.0\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AimXkFvuLIp_",
        "colab_type": "code",
        "outputId": "158dd318-bdc1-4c8a-cdc1-a37399c3fe65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqF_j4oJLKZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/WebProject/labeledTrainData.csv\", delimiter=\"\\t\",names=[\"tweet\", \"label\", \"labelValue\"])\n",
        "#data = pd.read_csv(\"/content/drive/My Drive/WebProject/preprocessed_tweets.csv\", delimiter=\"\\t\",names=[\"tweet\", \"label\", \"labelValue\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmTPyGQkLP08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"label\"].replace({\"spam\": \"neutral\", \"normal\": \"neutral\"}, inplace=True)\n",
        "data[\"label\"].replace({\"neutral\":1, \"abusive\": 2,\"hateful\":3}, inplace=True)\n",
        "\n",
        "#data.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypCPbXC3_Wda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_tweet(tweet):\n",
        "\n",
        "    # 1. Remove URLs, emojis, mentions, smileys using tweet-preprocessor library\n",
        "    # should not remove hashtags as hashtags contains important tweet content.\n",
        "    \n",
        "    #p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION,p.OPT.RESERVED,\tp.OPT.SMILEY,p.OPT.NUMBER)\n",
        "    clean = p.clean(tweet)\n",
        "    # 2. Remove HTML tags using Beautiful soup library\n",
        "    no_tag = BeautifulSoup(clean).get_text()\n",
        "\n",
        "    # 3. Expanding hashtags.\n",
        "    \n",
        "    #tweets_expanded = expand_hashtags(no_tag)\n",
        "\n",
        "    # 4. Remove non letter char using re\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\",\" \", no_tag)\n",
        "    #letters_only = re.sub(\"[^a-zA-Z]\",\" \", tweets_expanded)\n",
        "    \n",
        "    # 5. Convert to lower case\n",
        "    lower_case = letters_only.lower()\n",
        "    words = lower_case.split()\n",
        "\n",
        "    new_words = []\n",
        "    ps = PorterStemmer() \n",
        "    for w in words:\n",
        "        new_words.append(ps.stem(w))\n",
        "    # for w in words:\n",
        "    #     new_words.append(w)\n",
        "    # print(new_words[0:4])\n",
        "    # 5. Remove stop words\n",
        "    stops = set(stopwords.words(\"english\")) \n",
        "    final_words = [w for w in new_words if not w in stops]\n",
        "    # final_words = new_words\n",
        "\n",
        "    return(\" \".join( final_words ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3DDQePG_vvR",
        "colab_type": "code",
        "outputId": "c835690f-9b71-4bba-f54f-d58a3a5c2601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data['tweet'][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Beats by Dr. Dre urBeats Wired In-Ear Headphones - White https://t.co/9tREpqfyW4 https://t.co/FCaWyWRbpE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB04tgec_XoB",
        "colab_type": "code",
        "outputId": "0717b1d4-572c-45ef-9179-7ab0e9a04948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "num_tweets = data[\"tweet\"].size\n",
        "# print(num_tweets)\n",
        "for i in range(num_tweets):\n",
        "    data[\"tweet\"][i] = preprocess_tweet(data[\"tweet\"][i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdcg_Inki_hX",
        "colab_type": "code",
        "outputId": "3cc3e8d6-a0c9-4767-a8ef-2637d8425ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>labelValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beat dr dre urbeat wire ear headphon white</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>man would fuck rule parti wa perpetu warfar</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>time draw close father draw near alway</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>notic start act differ distant bc peep someth ...</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>forget unfollow believ grow new follow last da...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  label  labelValue\n",
              "0         beat dr dre urbeat wire ear headphon white      1           4\n",
              "1        man would fuck rule parti wa perpetu warfar      2           4\n",
              "2             time draw close father draw near alway      1           4\n",
              "3  notic start act differ distant bc peep someth ...      1           5\n",
              "4  forget unfollow believ grow new follow last da...      1           3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zXBCPXxnPmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "880UTQSUnSFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop(columns=\"labelValue\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5mjKXDqm4hx",
        "colab_type": "code",
        "outputId": "abd018ce-9ed5-4b09-f48b-0ac9bf300ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beat dr dre urbeat wire ear headphon white</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>man would fuck rule parti wa perpetu warfar</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>time draw close father draw near alway</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>notic start act differ distant bc peep someth ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>forget unfollow believ grow new follow last da...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  label\n",
              "0         beat dr dre urbeat wire ear headphon white      1\n",
              "1        man would fuck rule parti wa perpetu warfar      2\n",
              "2             time draw close father draw near alway      1\n",
              "3  notic start act differ distant bc peep someth ...      1\n",
              "4  forget unfollow believ grow new follow last da...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y03L3EwU1g8A",
        "colab_type": "code",
        "outputId": "9359af60-fe12-4d70-fdd8-af2e3d8ad669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "data['tweet_length'] = [len(text.split(' ')) for text in data.tweet]\n",
        "\n",
        "data['tweet_length'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9     10983\n",
              "10    10893\n",
              "8     10645\n",
              "7      9894\n",
              "11     9528\n",
              "6      8373\n",
              "12     7532\n",
              "5      6969\n",
              "13     5672\n",
              "4      5660\n",
              "3      3423\n",
              "14     3400\n",
              "2      2104\n",
              "15     1955\n",
              "16     1081\n",
              "1       856\n",
              "17      572\n",
              "18      244\n",
              "19      115\n",
              "20       54\n",
              "22       14\n",
              "21       13\n",
              "23        6\n",
              "24        5\n",
              "25        2\n",
              "30        2\n",
              "26        1\n",
              "Name: tweet_length, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nKl3jp72-FW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "data = data[data['tweet_length']>3]\n",
        "\n",
        "data = data.drop_duplicates(subset=['tweet'])\n",
        "\n",
        "data['tweet_BERT'] = '[CLS] '+data.tweet\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oGQhW-635v7",
        "colab_type": "code",
        "outputId": "98579904-6d09-40ab-8458-fa1987b184fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82027"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUdEzfFGj201",
        "colab_type": "code",
        "outputId": "f9a44b61-a6e0-4a14-c8c1-40999685ce2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.12.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.15.43)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.5)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.43->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 56.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 53.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 54.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=6e821998ad271d85fdd5408b2e447cf46a7abefd768697a40aae5e15e559c71b\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NNGMtm_3Jtn",
        "colab_type": "code",
        "outputId": "5e76ad3b-0fe9-4251-a0eb-eee3556b3fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "data['tweet_BERTbase_length'] = [len(tokenizer.tokenize(sent)) for sent in data.tweet_BERT]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 2529811.27B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAcMY_Cd170-",
        "colab_type": "code",
        "outputId": "0b37fe74-f4f9-4e0d-d878-71742ad1e564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet_length</th>\n",
              "      <th>tweet_BERT</th>\n",
              "      <th>tweet_BERTbase_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beat dr dre urbeat wire ear headphon white</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>[CLS] beat dr dre urbeat wire ear headphon white</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>man would fuck rule parti wa perpetu warfar</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>[CLS] man would fuck rule parti wa perpetu warfar</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>time draw close father draw near alway</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>[CLS] time draw close father draw near alway</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>notic start act differ distant bc peep someth ...</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>[CLS] notic start act differ distant bc peep s...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>forget unfollow believ grow new follow last da...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>[CLS] forget unfollow believ grow new follow l...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  ...  tweet_BERTbase_length\n",
              "0         beat dr dre urbeat wire ear headphon white  ...                     12\n",
              "1        man would fuck rule parti wa perpetu warfar  ...                     13\n",
              "2             time draw close father draw near alway  ...                      9\n",
              "3  notic start act differ distant bc peep someth ...  ...                     19\n",
              "4  forget unfollow believ grow new follow last da...  ...                     16\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW5Wr8cjmGIg",
        "colab_type": "code",
        "outputId": "858ee7cb-d71e-4ba2-f7e0-2302bdce63f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "label_dict = dict()\n",
        "for i, l in enumerate(list(data.label.value_counts().keys())):\n",
        "    label_dict.update({l: i})\n",
        "# for each unique label, assign a numeric identiifer\n",
        "data['type_label'] = [label_dict[i] for i in data.label] #create a column in df to store the numeric ids\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet_length</th>\n",
              "      <th>tweet_BERT</th>\n",
              "      <th>tweet_BERTbase_length</th>\n",
              "      <th>type_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beat dr dre urbeat wire ear headphon white</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>[CLS] beat dr dre urbeat wire ear headphon white</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>man would fuck rule parti wa perpetu warfar</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>[CLS] man would fuck rule parti wa perpetu warfar</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>time draw close father draw near alway</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>[CLS] time draw close father draw near alway</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>notic start act differ distant bc peep someth ...</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>[CLS] notic start act differ distant bc peep s...</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>forget unfollow believ grow new follow last da...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>[CLS] forget unfollow believ grow new follow l...</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  ...  type_label\n",
              "0         beat dr dre urbeat wire ear headphon white  ...           0\n",
              "1        man would fuck rule parti wa perpetu warfar  ...           1\n",
              "2             time draw close father draw near alway  ...           0\n",
              "3  notic start act differ distant bc peep someth ...  ...           0\n",
              "4  forget unfollow believ grow new follow last da...  ...           0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuQfgO58MgYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hateful = data[\"label\"]==3\n",
        "hateful = data[hateful]\n",
        "hateful = hateful.sample(frac=1)\n",
        "hateful = hateful.reset_index(drop=True)\n",
        "# hateful = hateful[:4333]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJjFKw8-NFpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abusive = data[\"label\"]==2\n",
        "abusive = data[abusive]\n",
        "abusive = abusive.sample(frac=1)\n",
        "abusive = abusive.reset_index(drop=True)\n",
        "# abusive = abusive[:4333]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXwW--AmNMqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neutral = data[\"label\"]==1\n",
        "neutral = data[neutral]\n",
        "neutral = neutral.sample(frac=1)\n",
        "neutral = neutral.reset_index(drop=True)\n",
        "# neutral = neutral[:4334]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3OG7vjXOTkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "union = pd.concat([hateful, abusive,neutral])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGf1CQXkOpAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "union = union.sample(frac=1)\n",
        "union = union.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOi3ZmdvgMvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_data = union[:10000]\n",
        "# validation_data = union[10000:11000]\n",
        "# test_data = union[11000:13000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oms4I5UPDkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = union[:69996]\n",
        "validation_data = union[69996:79996]\n",
        "test_data = union[79996:99996]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAtEFFQ5kxAb",
        "colab_type": "code",
        "outputId": "ed05221e-53ed-483b-8525-238cf8f95272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train_data[:1000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet_length</th>\n",
              "      <th>tweet_BERT</th>\n",
              "      <th>tweet_BERTbase_length</th>\n",
              "      <th>type_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wa highlight day see everyon speak us</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>[CLS] wa highlight day see everyon speak us</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eventid cf mobil event abandon vehicl hanumant...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>[CLS] eventid cf mobil event abandon vehicl ha...</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>comment section fuck disast</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>[CLS] comment section fuck disast</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lost children miscarriag think plain cruel danger</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>[CLS] lost children miscarriag think plain cru...</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>avoid cost travel boost health today day</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>[CLS] avoid cost travel boost health today day</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>damn happen nigga sing panda retard one</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>[CLS] damn happen nigga sing panda retard one</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>pleas look europ happen soon usa action taken</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>[CLS] pleas look europ happen soon usa action ...</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>watch exclus trailer intro upcom mixtap</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>[CLS] watch exclus trailer intro upcom mixtap</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>synchro arc wa b ad mostli gave us great op al...</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>[CLS] synchro arc wa b ad mostli gave us great...</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>music dannydr ft henri knight ring alarm prod ...</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>[CLS] music dannydr ft henri knight ring alarm...</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 tweet  ...  type_label\n",
              "0                wa highlight day see everyon speak us  ...           0\n",
              "1    eventid cf mobil event abandon vehicl hanumant...  ...           0\n",
              "2                          comment section fuck disast  ...           1\n",
              "3    lost children miscarriag think plain cruel danger  ...           0\n",
              "4             avoid cost travel boost health today day  ...           0\n",
              "..                                                 ...  ...         ...\n",
              "995            damn happen nigga sing panda retard one  ...           2\n",
              "996      pleas look europ happen soon usa action taken  ...           0\n",
              "997            watch exclus trailer intro upcom mixtap  ...           0\n",
              "998  synchro arc wa b ad mostli gave us great op al...  ...           2\n",
              "999  music dannydr ft henri knight ring alarm prod ...  ...           0\n",
              "\n",
              "[1000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCKq5VeJj6XL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import transformers\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "import math\n",
        "from typing import List\n",
        "from torch.nn.utils.rnn import pack_padded_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m8PuEmvhrYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_iter(data, batch_size, shuffle=False, bert=None):\n",
        "    \"\"\" Yield batches of sentences and labels reverse sorted by length (largest to smallest).\n",
        "    @param data (dataframe): dataframe with ProcessedText (str) and label (int) columns\n",
        "    @param batch_size (int): batch size\n",
        "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
        "    @param bert (str): whether for BERT training. Values: \"large\", \"base\", None\n",
        "    \"\"\"\n",
        "    batch_num = math.ceil(data.shape[0] / batch_size)\n",
        "    index_array = list(range(data.shape[0]))\n",
        "\n",
        "    if shuffle:\n",
        "        data = data.sample(frac=1)\n",
        "\n",
        "    for i in range(batch_num):\n",
        "        indices = index_array[i * batch_size: (i + 1) * batch_size]\n",
        "\n",
        "        if bert:\n",
        "            examples = data.iloc[indices].sort_values(by='tweet_BERTbase_length', ascending=False) #by='ProcessedText_BERT'+bert+'_length'\n",
        "            sents = list(examples.tweet_BERT)\n",
        "        else:\n",
        "            examples = data.iloc[indices].sort_values(by='tweet_length', ascending=False)\n",
        "            sents = [text.split(' ') for text in examples.tweet]\n",
        "\n",
        "        targets = list(examples.type_label.values)\n",
        "        yield sents, targets  # list[list[str]] if not bert else list[str], list[int]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAG08hRijomt",
        "colab_type": "code",
        "outputId": "5d5007d3-42ad-4469-db3a-b6030e7883b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "class CNN_Bert(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, bert_config, dropout_rate, n_class, out_channel=16):\n",
        "        \"\"\"\n",
        "        :param bert_config: str, BERT configuration description\n",
        "        :param device: torch.device\n",
        "        :param dropout_rate: float\n",
        "        :param n_class: int\n",
        "        :param out_channel: int, NOTE: out_channel per layer of BERT\n",
        "        \"\"\"\n",
        "\n",
        "        super(CNN_Bert, self).__init__()\n",
        "\n",
        "        self.bert_config = bert_config\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.n_class = n_class\n",
        "        self.out_channel = out_channel\n",
        "        self.bert = BertModel.from_pretrained(self.bert_config)\n",
        "        self.out_channels = self.bert.config.num_hidden_layers*self.out_channel\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(self.bert_config)\n",
        "        self.conv = torch.nn.Conv2d(in_channels=self.bert.config.num_hidden_layers,\n",
        "                              out_channels=self.out_channels,\n",
        "                              kernel_size=(3, self.bert.config.hidden_size),\n",
        "                              groups=self.bert.config.num_hidden_layers)\n",
        "        self.hidden_to_softmax = torch.nn.Linear(self.out_channels, self.n_class, bias=True)\n",
        "        self.dropout = torch.nn.Dropout(p=self.dropout_rate)\n",
        "\n",
        "    def forward(self, sents):\n",
        "        \"\"\"\n",
        "        :param sents:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        sents_tensor, masks_tensor, sents_lengths = sents_to_tensor(self.tokenizer, sents)\n",
        "        encoded_layers, pooled_output = self.bert(input_ids=sents_tensor, attention_mask=masks_tensor,\n",
        "                                                  output_all_encoded_layers=True)\n",
        "        encoded_stack_layer = torch.stack(encoded_layers, 1)  # (batch_size, channel, max_sent_length, hidden_size)\n",
        "\n",
        "        conv_out = self.conv(encoded_stack_layer)  # (batch_size, channel_out, some_length, 1)\n",
        "        conv_out = torch.squeeze(conv_out, dim=3)  # (batch_size, channel_out, some_length)\n",
        "        conv_out, _ = torch.max(conv_out, dim=2)  # (batch_size, channel_out)\n",
        "        pre_softmax = self.hidden_to_softmax(conv_out)\n",
        "\n",
        "        return pre_softmax\n",
        "\n",
        "    @staticmethod\n",
        "    def load(model_path: str):\n",
        "        \"\"\" Load the model from a file.\n",
        "        @param model_path (str): path to model\n",
        "        @return model (nn.Module): model with saved parameters\n",
        "        \"\"\"\n",
        "        params = torch.load(model_path)\n",
        "        args = params['args']\n",
        "        model = CNN_Bert( **args)\n",
        "        model.load_state_dict(params['state_dict'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def save(self, path: str):\n",
        "        \"\"\" Save the model to a file.\n",
        "        @param path (str): path to the model\n",
        "        \"\"\"\n",
        "        print('save model parameters to [%s]' % path, file=sys.stderr)\n",
        "\n",
        "        params = {\n",
        "            'args': dict(bert_config=self.bert_config, out_channel=self.out_channel,\n",
        "                         dropout_rate=self.dropout_rate, n_class=self.n_class),\n",
        "            'state_dict': self.state_dict()\n",
        "        }\n",
        "\n",
        "        torch.save(params, path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-e4a50382092d>\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    encoded_stack_layer = torch.stackencoded_layers, 1)  # (batch_size, channel, max_sent_length, hidden_size)\u001b[0m\n\u001b[0m                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFg27JlMjwIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sents(sents, pad_token):\n",
        "    \"\"\" Pad list of sentences to the longest length in the batch.\n",
        "    @param sents (list[list[str]]): list of tokenized strings\n",
        "    @param pad_token (int): pad token\n",
        "    @returns sents_padded (list[list[int]]): list of tokenized sentences with padding shape: (batch_size, max_sentence_length)\n",
        "    \"\"\"\n",
        "    sents_padded = []\n",
        "    max_len = max(len(s) for s in sents)\n",
        "    for s in sents:\n",
        "      padded = [pad_token] * max_len\n",
        "      padded[:len(s)] = s\n",
        "      sents_padded.append(padded)\n",
        "    return sents_padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqxbxe8IkIFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sents_to_tensor(tokenizer, sents):\n",
        "    \"\"\"\n",
        "    :param tokenizer\n",
        "    :param sents: list[str], list of untokenized strings\n",
        "    \"\"\"\n",
        "    #print(\"SENTS::\", sents)\n",
        "    tokens_list = [tokenizer.tokenize(sent) for sent in sents]\n",
        "    #print(\"TOKENS_LIST\", tokens_list)\n",
        "    sents_lengths = [len(tokens) for tokens in tokens_list]\n",
        "    #print(\"SENTS_LENGTH::\", sents_lengths)\n",
        "    sents_lengths = torch.tensor(sents_lengths)\n",
        "    tokens_list_padded = pad_sents(tokens_list, '[PAD]')\n",
        "    masks = np.asarray(tokens_list_padded)!='[PAD]'\n",
        "    masks_tensor = torch.tensor(masks, dtype=torch.long)\n",
        "    tokens_id_list = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokens_list_padded]\n",
        "    sents_tensor = torch.tensor(tokens_id_list, dtype=torch.long)\n",
        "    \n",
        "    return sents_tensor, masks_tensor, sents_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbGKKZEo2lJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, path='cm', cmap=plt.cm.Reds):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    pickle.dump(cm, open(path, 'wb'))\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm0x1ihpkKIS",
        "colab_type": "code",
        "outputId": "dc7b9b96-a019-4ec0-8cfa-f2a8a3db2b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install bert-tensorflow\n",
        "!pip install utils\n",
        "import bert\n",
        "from pytorch_pretrained_bert import BertAdam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import time\n",
        "import sys\n",
        "import utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Requirement already satisfied: utils in /usr/local/lib/python3.6/dist-packages (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l032inz4kMV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(model, df_val, loss_func, bert_size):\n",
        "    \"\"\" validation of model during training.\n",
        "    @param model (nn.Module): the model being trained\n",
        "    @param df_val (dataframe): validation dataset, sorted in descending text length\n",
        "    @param loss_func(nn.Module): loss function\n",
        "    @return avg loss value across validation dataset\n",
        "    \"\"\"\n",
        "    was_training = model.training\n",
        "    model.eval() #model.eval() put all layers in model in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n",
        "    df_val = df_val.sort_values(by='tweet_BERTbase_length', ascending=False)\n",
        "    tweet_proc_bert = list(df_val['tweet_BERT'])\n",
        "    type_label = list(df_val['type_label'])\n",
        "    \n",
        "    val_batch_size = 32\n",
        "    num_val_samples = df_val.shape[0]\n",
        "    \n",
        "    n_batch = int(np.ceil(num_val_samples/val_batch_size))\n",
        "    \n",
        "    total_loss = 0.\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i in range(n_batch):\n",
        "            sents = tweet_proc_bert[i*val_batch_size: (i+1)*val_batch_size]\n",
        "            targets = torch.tensor(type_label[i*val_batch_size: (i+1)*val_batch_size],\n",
        "                                   dtype=torch.long)\n",
        "            batch_size = len(sents)\n",
        "            output = model(sents)\n",
        "            batch_loss = loss_func(output, targets)\n",
        "            total_loss += batch_loss.item()*batch_size\n",
        "    \n",
        "    if was_training:\n",
        "        model.train()\n",
        "    \n",
        "    return total_loss/num_val_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5fQ_a6VkP9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model():\n",
        "    \n",
        "    label_name = ['neutral', 'abusive', 'hateful']\n",
        "    bert_config_str = 'bert-base-uncased'\n",
        "    bert_size = bert_config_str.split('-')[1]\n",
        "\n",
        "    start_time = time.time()\n",
        "    print('Importing data...', file=sys.stderr)\n",
        "    \n",
        "    df_train = train_data\n",
        "    df_val = validation_data\n",
        "    train_label = dict(df_train['type_label'].value_counts())\n",
        "    label_max = float(max(train_label.values()))\n",
        "\n",
        "    print(train_label, file=sys.stderr)\n",
        "    train_label_weight = torch.tensor([label_max/train_label[i] for i in range(len(train_label))])\n",
        "    print('Done! time elapsed %.2f sec' % (time.time() - start_time), file=sys.stderr)\n",
        "    print('-' * 80, file=sys.stderr)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    print('Set up model...', file=sys.stderr)\n",
        "    lr_bert = 2e-5\n",
        "    lr = 1e-3\n",
        "    model_name = 'CNN_bert'\n",
        "    dropout = 0.3\n",
        "    clip_grad = 1.0\n",
        "    max_epoch = 3\n",
        "   \n",
        "    # model = CNN_Bert(num_class=len(label_name), dropout_rate= dropout, bert_config= 'bert-base-uncased', out_channel=16)\n",
        "    model = CNN_Bert(bert_config = 'bert-base-uncased', n_class=len(label_name), dropout_rate= dropout)\n",
        "    optimizer_grouped_parameters = [\n",
        "                {'params': model.bert.parameters()},\n",
        "                {'params': model.conv.parameters(), 'lr': float(lr)},\n",
        "                {'params': model.hidden_to_softmax.parameters(), 'lr': float(lr)}]\n",
        "\n",
        "    optimizer = BertAdam( optimizer_grouped_parameters, \n",
        "                         lr=lr_bert,\n",
        "                         max_grad_norm=clip_grad )\n",
        "            \n",
        "        \n",
        "    print('Done! time elapsed %.2f sec' % (time.time() - start_time), file=sys.stderr)\n",
        "    print('-' * 80, file=sys.stderr)\n",
        "    \n",
        "    model.train() #set model for training mode\n",
        "    criterion = torch.nn.CrossEntropyLoss(weight=train_label_weight, reduction='mean')\n",
        "    torch.save(criterion, 'loss_func')  # for later testing\n",
        "\n",
        "    train_batch_size = 64\n",
        "    valid_niter =  500\n",
        "    display_num = 10\n",
        "    \n",
        "    num_restarts = 0\n",
        "    max_num_trial = 3\n",
        "    train_iter = patience = cum_loss = report_loss = 0\n",
        "    total_samples = display_samples = epoch = 0\n",
        "    lr_decay = 0.5\n",
        "    patience_max = 3\n",
        "    valid_loss_hist = []\n",
        "    train_time = begin_time = time.time()\n",
        "    print('Begin training...')\n",
        "    \n",
        "    # while True:\n",
        "    while train_iter < 600:\n",
        "        epoch += 1\n",
        "        for sents, targets in batch_iter(df_train, batch_size=train_batch_size, shuffle=False, bert = bert_config_str):  # for each epoch\n",
        "            train_iter += 1\n",
        "            \n",
        "            batch_size = len(sents)\n",
        "            labels = torch.tensor(targets, dtype=torch.long)\n",
        "            \n",
        "            optimizer.zero_grad() #restarting the grad accumulations between mini-batches\n",
        "            output = model(sents) #pass through model\n",
        "            loss = criterion(output, labels) #calculate loss\n",
        "            loss.backward() #back prop\n",
        "            optimizer.step() #update weights\n",
        "            \n",
        "            batch_losses_val = loss.item() * batch_size\n",
        "            report_loss += batch_losses_val\n",
        "            cum_loss += batch_losses_val\n",
        "            \n",
        "            display_samples += batch_size\n",
        "            total_samples += batch_size\n",
        "            \n",
        "            if train_iter % display_num == 0:\n",
        "                print('epoch %d, iter %d, avg. loss %.2f, '\n",
        "                      'total samples %d, speed %.2f samples/sec, '\n",
        "                      'time elapsed %.2f sec' % \n",
        "                      (epoch, train_iter, report_loss / display_samples,\n",
        "                       total_samples, display_samples / (time.time() - train_time),\n",
        "                       time.time() - begin_time), file=sys.stderr)\n",
        "                train_time = time.time()\n",
        "                report_loss = display_samples = 0.\n",
        "            \n",
        "            # perform validation\n",
        "            if train_iter % valid_niter == 0:\n",
        "                print('epoch %d, iter %d, cum. loss %.2f, cum. examples %d' % \n",
        "                      (epoch, train_iter, cum_loss / total_samples, total_samples), file=sys.stderr)\n",
        "                cum_loss = total_samples = 0.\n",
        "                \n",
        "                print('begin validation ...', file=sys.stderr)\n",
        "                \n",
        "                valid_loss = validation(model, df_val, criterion, bert_size=bert_size)\n",
        "                print('validation: iter %d, loss %f' % (train_iter, valid_loss), file=sys.stderr)\n",
        "                \n",
        "                improved_loss = len(valid_loss_hist)==0 or valid_loss < min(valid_loss_hist)\n",
        "                valid_loss_hist.append(valid_loss)\n",
        "                \n",
        "                if improved_loss:\n",
        "                    patience = 0\n",
        "                    print('save currently the best model to [%s]' % model_name +'_model.bin', file=sys.stderr)\n",
        "                    model.save(model_name+'_model.bin')\n",
        "                    \n",
        "                    # also save the optimizers' state\n",
        "                    torch.save(optimizer.state_dict(), model_name + '.optim')\n",
        "                else: #if valid loss did not improve\n",
        "                    patience += 1\n",
        "                    print('hit patience %d out of %d' % (patience, int(patience_max)), file=sys.stderr)\n",
        "\n",
        "                    if patience < int(patience_max):\n",
        "                        num_restarts += 1\n",
        "                        print('hit #%d restart out of max %d restarts' % (num_restarts, int(max_num_trial)), file=sys.stderr)\n",
        "\n",
        "                        if num_restarts >= int(max_num_trial):\n",
        "                            print('early termination!', file=sys.stderr)\n",
        "                            exit(0)\n",
        "                        \n",
        "                        lr = optimizer.param_groups[0]['lr'] * float(lr_decay)\n",
        "                        print('load previously best model and decay learning rate to %f' % lr, file=sys.stderr)\n",
        "                        \n",
        "                        # load model\n",
        "                        params = torch.load(model_name + '_model.bin')\n",
        "                        model.load_state_dict(params['state_dict'])\n",
        "                        \n",
        "                        print('restore parameters of the optimizers', file=sys.stderr)\n",
        "                        optimizer.load_state_dict(torch.load(model_name + '.optim'))\n",
        "                        \n",
        "                        # set new lr\n",
        "                        for param_group in optimizer.param_groups:\n",
        "                            param_group['lr'] = lr\n",
        "                            \n",
        "                        # reset patience\n",
        "                        patience = 0\n",
        "                        \n",
        "                if epoch == max_epoch:\n",
        "                    print('reached maximum number of epochs!', file=sys.stderr)\n",
        "                    exit(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl5IoX_6oFe9",
        "colab_type": "code",
        "outputId": "f36c7ecc-ada5-47e5-e41c-1294ad9f6114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Importing data...\n",
            "{0: 7293, 1: 2266, 2: 441}\n",
            "Done! time elapsed 0.00 sec\n",
            "--------------------------------------------------------------------------------\n",
            "Set up model...\n",
            "t_total value of -1 results in schedule not being applied\n",
            "Done! time elapsed 6.01 sec\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Begin training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1, iter 10, avg. loss 1.96, total samples 640, speed 21.70 samples/sec, time elapsed 29.50 sec\n",
            "epoch 1, iter 20, avg. loss 1.17, total samples 1280, speed 23.03 samples/sec, time elapsed 57.29 sec\n",
            "epoch 1, iter 30, avg. loss 0.93, total samples 1920, speed 23.14 samples/sec, time elapsed 84.94 sec\n",
            "epoch 1, iter 40, avg. loss 0.85, total samples 2560, speed 22.40 samples/sec, time elapsed 113.52 sec\n",
            "epoch 1, iter 50, avg. loss 0.65, total samples 3200, speed 21.40 samples/sec, time elapsed 143.43 sec\n",
            "epoch 1, iter 60, avg. loss 0.69, total samples 3840, speed 21.58 samples/sec, time elapsed 173.09 sec\n",
            "epoch 1, iter 70, avg. loss 0.64, total samples 4480, speed 21.31 samples/sec, time elapsed 203.13 sec\n",
            "epoch 1, iter 80, avg. loss 0.86, total samples 5120, speed 20.80 samples/sec, time elapsed 233.90 sec\n",
            "epoch 1, iter 90, avg. loss 0.97, total samples 5760, speed 22.07 samples/sec, time elapsed 262.90 sec\n",
            "epoch 1, iter 100, avg. loss 0.52, total samples 6400, speed 21.63 samples/sec, time elapsed 292.50 sec\n",
            "epoch 1, iter 110, avg. loss 0.72, total samples 7040, speed 22.72 samples/sec, time elapsed 320.66 sec\n",
            "epoch 1, iter 120, avg. loss 0.85, total samples 7680, speed 23.09 samples/sec, time elapsed 348.38 sec\n",
            "epoch 1, iter 130, avg. loss 0.73, total samples 8320, speed 22.66 samples/sec, time elapsed 376.63 sec\n",
            "epoch 1, iter 140, avg. loss 0.59, total samples 8960, speed 23.25 samples/sec, time elapsed 404.16 sec\n",
            "epoch 1, iter 150, avg. loss 0.58, total samples 9600, speed 22.60 samples/sec, time elapsed 432.48 sec\n",
            "epoch 2, iter 160, avg. loss 0.54, total samples 10192, speed 20.34 samples/sec, time elapsed 461.58 sec\n",
            "epoch 2, iter 170, avg. loss 0.54, total samples 10832, speed 19.98 samples/sec, time elapsed 493.62 sec\n",
            "epoch 2, iter 180, avg. loss 0.31, total samples 11472, speed 21.07 samples/sec, time elapsed 523.99 sec\n",
            "epoch 2, iter 190, avg. loss 0.30, total samples 12112, speed 21.73 samples/sec, time elapsed 553.44 sec\n",
            "epoch 2, iter 200, avg. loss 0.35, total samples 12752, speed 20.22 samples/sec, time elapsed 585.10 sec\n",
            "epoch 2, iter 210, avg. loss 0.27, total samples 13392, speed 21.45 samples/sec, time elapsed 614.94 sec\n",
            "epoch 2, iter 220, avg. loss 0.36, total samples 14032, speed 19.66 samples/sec, time elapsed 647.49 sec\n",
            "epoch 2, iter 230, avg. loss 0.36, total samples 14672, speed 20.09 samples/sec, time elapsed 679.34 sec\n",
            "epoch 2, iter 240, avg. loss 0.68, total samples 15312, speed 20.11 samples/sec, time elapsed 711.18 sec\n",
            "epoch 2, iter 250, avg. loss 0.40, total samples 15952, speed 19.89 samples/sec, time elapsed 743.36 sec\n",
            "epoch 2, iter 260, avg. loss 0.32, total samples 16592, speed 19.53 samples/sec, time elapsed 776.13 sec\n",
            "epoch 2, iter 270, avg. loss 0.29, total samples 17232, speed 20.14 samples/sec, time elapsed 807.91 sec\n",
            "epoch 2, iter 280, avg. loss 0.45, total samples 17872, speed 21.52 samples/sec, time elapsed 837.65 sec\n",
            "epoch 2, iter 290, avg. loss 0.59, total samples 18512, speed 21.52 samples/sec, time elapsed 867.38 sec\n",
            "epoch 2, iter 300, avg. loss 0.36, total samples 19152, speed 22.66 samples/sec, time elapsed 895.62 sec\n",
            "epoch 2, iter 310, avg. loss 0.42, total samples 19792, speed 23.24 samples/sec, time elapsed 923.16 sec\n",
            "epoch 3, iter 320, avg. loss 0.23, total samples 20384, speed 21.85 samples/sec, time elapsed 950.25 sec\n",
            "epoch 3, iter 330, avg. loss 0.25, total samples 21024, speed 22.34 samples/sec, time elapsed 978.89 sec\n",
            "epoch 3, iter 340, avg. loss 0.15, total samples 21664, speed 23.16 samples/sec, time elapsed 1006.52 sec\n",
            "epoch 3, iter 350, avg. loss 0.12, total samples 22304, speed 23.32 samples/sec, time elapsed 1033.96 sec\n",
            "epoch 3, iter 360, avg. loss 0.14, total samples 22944, speed 22.09 samples/sec, time elapsed 1062.93 sec\n",
            "epoch 3, iter 370, avg. loss 0.11, total samples 23584, speed 22.42 samples/sec, time elapsed 1091.48 sec\n",
            "epoch 3, iter 380, avg. loss 0.13, total samples 24224, speed 23.17 samples/sec, time elapsed 1119.11 sec\n",
            "epoch 3, iter 390, avg. loss 0.20, total samples 24864, speed 22.16 samples/sec, time elapsed 1147.99 sec\n",
            "epoch 3, iter 400, avg. loss 0.21, total samples 25504, speed 22.04 samples/sec, time elapsed 1177.03 sec\n",
            "epoch 3, iter 410, avg. loss 0.19, total samples 26144, speed 21.81 samples/sec, time elapsed 1206.38 sec\n",
            "epoch 3, iter 420, avg. loss 0.19, total samples 26784, speed 23.67 samples/sec, time elapsed 1233.42 sec\n",
            "epoch 3, iter 430, avg. loss 0.25, total samples 27424, speed 23.16 samples/sec, time elapsed 1261.05 sec\n",
            "epoch 3, iter 440, avg. loss 0.19, total samples 28064, speed 23.44 samples/sec, time elapsed 1288.36 sec\n",
            "epoch 3, iter 450, avg. loss 0.21, total samples 28704, speed 23.33 samples/sec, time elapsed 1315.78 sec\n",
            "epoch 3, iter 460, avg. loss 0.16, total samples 29344, speed 23.07 samples/sec, time elapsed 1343.52 sec\n",
            "epoch 3, iter 470, avg. loss 0.25, total samples 29984, speed 24.08 samples/sec, time elapsed 1370.10 sec\n",
            "epoch 4, iter 480, avg. loss 0.17, total samples 30576, speed 22.35 samples/sec, time elapsed 1396.58 sec\n",
            "epoch 4, iter 490, avg. loss 0.24, total samples 31216, speed 23.32 samples/sec, time elapsed 1424.03 sec\n",
            "epoch 4, iter 500, avg. loss 0.12, total samples 31856, speed 23.79 samples/sec, time elapsed 1450.93 sec\n",
            "epoch 4, iter 500, cum. loss 0.46, cum. examples 31856\n",
            "begin validation ...\n",
            "validation: iter 500, loss 1.589250\n",
            "save currently the best model to [CNN_bert]_model.bin\n",
            "save model parameters to [CNN_bert_model.bin]\n",
            "epoch 4, iter 510, avg. loss 0.08, total samples 640, speed 14.77 samples/sec, time elapsed 1494.27 sec\n",
            "epoch 4, iter 520, avg. loss 0.07, total samples 1280, speed 22.86 samples/sec, time elapsed 1522.27 sec\n",
            "epoch 4, iter 530, avg. loss 0.05, total samples 1920, speed 23.18 samples/sec, time elapsed 1549.89 sec\n",
            "epoch 4, iter 540, avg. loss 0.04, total samples 2560, speed 23.24 samples/sec, time elapsed 1577.42 sec\n",
            "epoch 4, iter 550, avg. loss 0.16, total samples 3200, speed 23.31 samples/sec, time elapsed 1604.87 sec\n",
            "epoch 4, iter 560, avg. loss 0.10, total samples 3840, speed 22.24 samples/sec, time elapsed 1633.64 sec\n",
            "epoch 4, iter 570, avg. loss 0.09, total samples 4480, speed 21.81 samples/sec, time elapsed 1662.99 sec\n",
            "epoch 4, iter 580, avg. loss 0.09, total samples 5120, speed 23.60 samples/sec, time elapsed 1690.10 sec\n",
            "epoch 4, iter 590, avg. loss 0.12, total samples 5760, speed 23.69 samples/sec, time elapsed 1717.12 sec\n",
            "epoch 4, iter 600, avg. loss 0.10, total samples 6400, speed 23.46 samples/sec, time elapsed 1744.40 sec\n",
            "epoch 4, iter 610, avg. loss 0.07, total samples 7040, speed 23.71 samples/sec, time elapsed 1771.39 sec\n",
            "epoch 4, iter 620, avg. loss 0.07, total samples 7680, speed 23.76 samples/sec, time elapsed 1798.32 sec\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHOwK1jWBuS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model():\n",
        "\n",
        "    label_name = ['neutral', 'abusive', 'hateful']\n",
        "    model_name = 'CNN_bert'\n",
        "\n",
        "    prefix = 'CNN_bert'\n",
        "    bert_config_str = 'bert-base-uncased'\n",
        "    bert_size = bert_config_str.split('-')[1]\n",
        "\n",
        "    print('load best model...')\n",
        "    \n",
        "    model = CNN_Bert.load(model_name+'_model.bin')\n",
        "    print(\"Model loaded\")\n",
        "    model.eval()\n",
        "\n",
        "    df_test = test_data\n",
        "    df_test = df_test.sort_values(by='tweet_BERTbase_length', ascending=False)\n",
        "\n",
        "    test_batch_size = 32\n",
        "    n_batch = int(np.ceil(df_test.shape[0]/test_batch_size))\n",
        "\n",
        "    cn_loss = torch.load('loss_func')\n",
        "    tweet_proc_bert = list(df_test['tweet_BERT'])\n",
        "    type_label = list(df_test['type_label'])\n",
        "\n",
        "    test_loss = 0.\n",
        "    prediction = []\n",
        "    prob = []\n",
        "\n",
        "    softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(n_batch):\n",
        "            sents = tweet_proc_bert[i*test_batch_size: (i+1)*test_batch_size]\n",
        "            targets = torch.tensor(type_label[i * test_batch_size: (i + 1) * test_batch_size],\n",
        "                                   dtype=torch.long)\n",
        "            batch_size = len(sents)\n",
        "\n",
        "            pre_softmax = model(sents)\n",
        "            batch_loss = cn_loss(pre_softmax, targets)\n",
        "            test_loss += batch_loss.item()*batch_size\n",
        "            prob_batch = softmax(pre_softmax)\n",
        "            prob.append(prob_batch)\n",
        "\n",
        "            prediction.extend([t.item() for t in list(torch.argmax(prob_batch, dim=1))])\n",
        "\n",
        "    prob = torch.cat(tuple(prob), dim=0)\n",
        "    loss = test_loss/df_test.shape[0]\n",
        "\n",
        "    pickle.dump([label_name[i] for i in prediction], open(prefix+'_test_prediction', 'wb'))\n",
        "    pickle.dump(prob.data.cpu().numpy(), open(prefix + '_test_prediction_prob', 'wb'))\n",
        "    \n",
        "    accuracy = accuracy_score(df_test['type_label'].values, prediction)\n",
        "    f1 = f1_score(df_test['type_label'].values, prediction, average='weighted')\n",
        "\n",
        "    f1s = {}\n",
        "    for i in range(len(label_name)):\n",
        "        prediction_ = [1 if pred == i else 0 for pred in prediction]\n",
        "        true_ = [1 if label == i else 0 for label in df_test.type_label.values]\n",
        "        f1s.update({label_name[i]: f1_score(true_, prediction_)})\n",
        "\n",
        "    cm = plot_confusion_matrix(list(df_test['type_label'].values), prediction, label_name, normalize=False, path=prefix+'_confusion_matrix', title='Confusion matrix for BERT+CNN')\n",
        "    plt.savefig(prefix+'_confusion_matrix', format='png')\n",
        "\n",
        "    verbose = True\n",
        "    if verbose:\n",
        "        print('loss: %.2f' % loss)\n",
        "        print('accuracy: %.2f' % accuracy)\n",
        "        print('f1 score: %.2f' % f1)\n",
        "        print('-' * 80)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRf7bN-HF3iD",
        "colab_type": "code",
        "outputId": "c9cabe7a-1ce0-48b5-d1e0-dec847d36d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "test_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load best model...\n",
            "Model loaded\n",
            "loss: 1.69\n",
            "accuracy: 0.90\n",
            "f1 score: 0.90\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSCuoqBdKyys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}